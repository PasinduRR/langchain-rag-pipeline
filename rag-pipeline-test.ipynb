{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f550ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "baff67d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'example.txt'}, page_content='Prompt engineering is like giving clear directions to a super-smart but slightly confused friend. Without guidance, large language models (LLMs) like Googleâ€™s Gemini, ChatGPT, DeepSeek can churn out vague or off-target answers. Googleâ€™s whitepaper, by Lee Boonstra, explains that LLMs predict the next word based on their training and your input.\\nA sloppy prompt means sloppy results, a clear prompt delivers exactly what you need.\\nThese techniques, echoed in tips shared across tech communities, help anyone, beginners or experts, make AI shine for everyday tasks like writing, planning, or brainstorming.\\nLetâ€™s dive into the 10 easy ways to level up your AI game.')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Ingestion\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"example.txt\")\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "135dfe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Not Everything Is an LLM: 8 AI Model Types You Need to Know in 2025 \\nBeyond ChatGPT, A beginner’s guide to today’s essential AI models \\n \\n \\nIn 2023, if you said “AI”, most people thought of ChatGPT. \\nFast-forward to 2025, and the landscape looks very different. LLMs (Large Language \\nModels) may have ignited the AI revolution, but now we’re deep into an era of specialized \\nAI models, each designed with a specific superpower. \\nYet, somehow, everyone still calls them LLMs. \\nIt’s like calling every vehicle a “car”, whether it’s a bicycle, a truck, or a plane. Sure, they all \\nmove, but they’re built for very different purposes. \\nIf you’re an AI researcher, startup founder, PM, or just someone trying to keep up, \\nunderstanding the difference between an LLM, LAM, SLM, MoE, and more is no longer a \\nnice-to-have. \\nIt’s a competitive edge.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='So, Let’s break down 8 powerful AI model types and what they’re really built to do. \\n1. LLM — Large Language Model \\nWhat Is an LLM, Really? \\n \\nDiagram drawn using Draw.io (by the author) \\nImagine you’re texting a super-intelligent friend who can complete your sentences, write \\nessays, debug code, and even pretend to be Shakespeare, all in one breath. \\nThat’s essentially what an LLM (Large Language Model) does. \\nLLMs are trained on massive amounts of text from the internet, books, articles, code, \\ntweets to learn how language works. \\nTheir goal? To predict the next word (or token) in a sequence, based on everything that \\ncame before. \\nThink of it like supercharged autocomplete, but instead of just finishing your sentence, it \\ncan write an entire book, answer philosophical questions, or build a working website. \\nWhy Are LLMs So Popular? \\nThey became the poster child of AI in recent years for a few reasons, \\n• Conversational Power: ChatGPT, Claude, Gemini — all powered by LLMs. \\n• Code + Content: From blog articles to Python scripts, LLMs handle creative and \\ntechnical tasks. \\n• General Knowledge: They “know” a bit about almost everything, making them \\ngreat general-purpose tools. \\nReal-World Use Cases \\n• Writing and rewriting content'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='• Programming assistance and code generation \\n• Customer service chatbots \\n• Brainstorming ideas \\n• Language translation \\n• Education and tutoring \\nIn short, if it involves words, LLMs are likely involved. \\nBut There’s a Catch… \\nWhile LLMs seem magical, they have limitations, \\n• They can hallucinate (make things up confidently) \\n• They’re computationally expensive to run \\n• They lack true understanding or reasoning, they’re guessing based on patterns \\nThat’s why new model types, built for speed, specialization, or deeper reasoning are \\nemerging fast. \\n2. LCM — Latent Consistency Model \\nWhat Is an LCM, and Why Should You Care? \\n \\nDiagram drawn using Draw.io (by the author) \\nPicture this: you’re using an AI image generator on your phone, and it gives you a crisp \\nresult in under a second, no cloud connection, no heavy lifting. \\nThat’s the power of LCMs (Latent Consistency Models).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Unlike LLMs that generate text, LCMs are designed primarily for images, and they’re \\noptimized for speed, efficiency, and small devices. They’re the fast, lightweight cousins \\nof the more heavyweight image generation models like Stable Diffusion. \\nThink of LCMs as the real-time engines of the AI world, designed to work smoothly even on \\nmobile devices or low-powered edge hardware. \\nHow Do They Work? \\nLCMs build on the concept of diffusion models, a class of models that gradually “denoise” \\nrandom patterns into meaningful images. But instead of needing dozens of slow steps to do \\nthis, LCMs shortcut the process by learning consistent patterns in a compressed \\n(latent) space. \\nImagine sketching a face. A normal model draws 50 lines slowly. LCM? Just a few confident \\nstrokes and it’s done. \\nReal-World Use Cases \\n• On-device image generation (think AI filters or avatars) \\n• AR/VR applications where speed is critical \\n• Faster prototyping tools for designers \\n• Real-time vision enhancement on smart cameras \\nIn essence, LCMs are the go-to model when you want fast, beautiful results without \\nneeding a supercomputer. \\nWhy They Matter in 2025 \\nWe’re moving into an era of edge computing, where devices generate content locally for \\nspeed and privacy. LCMs are a big part of this shift. \\nIn the future, your smart glasses or smartwatch might generate and enhance images using \\nan LCM, all on the fly. \\n3. LAM — Language Action Model \\nWhat Exactly Is a LAM?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='Diagram drawn using Draw.io (by the author) \\nIf an LLM is your chatty friend and an LCM is your quick-drawing artist, then a LAM is your \\nsmart assistant that plans, remembers, and executes tasks. \\nLAM (Language Action Model) bridges the gap between understanding language and \\ntaking meaningful actions. It doesn’t just generate text, it understands intent, \\nremembers context, and interacts with tools or environments. \\nThink of LAMs as the backbone of AI agents, the kind of models that can help automate \\ntasks, operate software tools, or plan multi-step actions like booking a trip or debugging \\ncode. \\nHow Does It Work? \\nLAMs typically combine, \\n• LLMs for natural language understanding, \\n• Memory modules for keeping track of past actions or inputs, \\n• Planners that can break down complex tasks, \\n• Tool use capabilities to actually execute steps (e.g., via APIs or interfaces). \\nImagine asking your AI, “Book a flight to Tokyo, compare hotel prices, and set a \\nreminder for my visa appointment. ” \\nA pure LLM might just give you suggestions. \\nA LAM? It acts, checking calendars, querying APIs, and building a task flow behind the \\nscenes.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Real-World Use Cases \\n• AI agents that automate workflows (e.g., Zapier AI, Devin) \\n• Digital assistants that interact with apps and services \\n• Customer support bots that solve problems, not just reply \\n• Productivity tools that complete tasks based on instructions \\n• Robotics, where language input controls physical actions \\nWhy LAMs Matter in 2025 \\nLLMs changed the game by understanding text. But LAMs are pushing things forward by \\ndoing things. \\nIn a world of increasing automation, LAMs are unlocking AI that can work across apps, \\nunderstand long-term goals, and adapt to changing environments. \\nImagine an AI that not only drafts your email but also sends it, follows up, and schedules a \\nmeeting, all based on one prompt. \\n4. MoE — Mixture of Experts \\nWhat Is a MoE Model? \\n \\nDiagram drawn using Draw.io (by the author)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Imagine you’re asking a big question and instead of getting an answer from one generalist, \\nyou’re directed to a team of specialists, each an expert in a narrow domain. \\nThat’s what MoE (Mixture of Experts) models do. \\nA Mixture of Experts model is made up of many sub-models (“experts”), but when a \\nprompt comes in, only a few experts are activated based on what’s relevant. This makes \\nthe model scalable and efficient, because not every expert is used every time. \\nThink of it like consulting the best surgeon for surgery, the best chef for cooking, and the \\nbest mechanic for your car, all within one AI. \\nHow It Works \\nMoE uses a “router”, a smart internal system that decides which expert(s) to activate \\nbased on your input. \\n• The router evaluates the input. \\n• It chooses the top N experts (often 2 out of 100+). \\n• Only those selected experts process the input and return an output. \\n• This output is combined and returned to the user. \\nSo you get targeted intelligence with minimal compute overhead. \\nReal-World Use Cases \\n• High-performance AI at scale (e.g., Google’s Switch Transformer, GShard) \\n• Efficient cloud inference — fewer resources, faster outputs \\n• Domain-specialized assistants (e.g., a medical expert vs. a legal expert) \\n• Multilingual systems — experts for different languages \\n• Fine-grained personalization — experts tuned to user behavior or tasks \\nWhy MoE Models Matter in 2025 \\nWith AI models growing into hundreds of billions of parameters, compute costs are \\nbecoming a bottleneck. MoE models provide a brilliant workaround, you scale wide \\nwithout scaling heavy. \\nBy activating only what’s needed, MoEs offer a massive increase in performance without \\nneeding supercomputers for every query.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Imagine a model that’s 10x larger but only costs as much to run as a model half its size. \\nThat’s the power of MoE. \\nThey also make way for more modular and expandable systems, where new experts can \\nbe added without retraining the entire model. \\n5. VLM — Vision Language Model \\nWhat Is a VLM? \\n \\nDiagram drawn using Draw.io (by the author) \\nImagine an AI that sees an image and reads your caption or query and then responds with \\ndeep understanding of both. \\nThat’s the magic of a Vision Language Model (VLM). These models are designed to \\nprocess and understand both visual and textual inputs simultaneously. \\nThey’re like the Swiss Army knife of AI, combining the perception of vision models with the \\nreasoning power of language models. \\nHow It Works \\nAt the core of a VLM is a shared embedding space, a special zone where images and text \\nare mapped into similar “meaningful” numerical representations. \\nThis allows the model to match images to descriptions, answer questions about visual \\ncontent, or even generate text from images and vice versa. \\nHere’s a simplified flow, \\n1. Image goes through a vision encoder (like a modified transformer or CNN).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='2. Text goes through a language encoder (like BERT or GPT). \\n3. Both are aligned in a shared latent space for cross-modal understanding. \\n4. The model produces outputs such as answers, captions, classifications, etc. \\nReal-World Use Cases \\n• Multimodal assistants (e.g., ChatGPT-4o, Gemini) \\n• Image captioning \\n• Visual question answering (VQA) \\n• Search engines that understand both text & image queries \\n• Accessibility tools (e.g., for visually impaired users) \\n• Robotics — interpreting surroundings using both vision and instruction \\n• AR/VR — contextual interaction with the real world \\nExample: You upload a photo of a cracked phone screen and ask, “Can I still use this?” A \\nVLM can analyze the image, understand the question, and respond helpfully. \\nWhy VLMs Matter in 2025 \\nIn a world where digital content is increasingly visual, we need models that go beyond \\ntext-only capabilities. VLMs are foundational to, \\n• Multimodal search \\n• Context-aware agents \\n• Assistive AI for real-world perception \\nThey are key to bridging the gap between language-driven interfaces and the visual-first \\nworld we live in, making AI more intuitive and human-friendly. \\nVLMs also serve as the building blocks for embodied AI. Systems that can “see, ” \\n“understand, ” and “act” in physical or virtual environments. \\n6. SLM — Small Language Model \\nWhat Is a Small Language Model?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Diagram drawn using Draw.io (by the author) \\nWhile LLMs grab the spotlight with their massive scale, Small Language Models (SLMs) \\nwork quietly in the background. On your phone, your laptop, or even your smart toaster. \\nSLMs are compact, efficient language models designed to deliver fast, low-latency \\nresponses on limited hardware. \\nThink of them as the LLM’s minimalistic cousin, less compute-hungry but still impressively \\ncapable. \\nHow It Works \\nSLMs are typically built using the same transformer architecture as LLMs, but with fewer \\nparameters and optimized inference paths. \\n• Parameter count: Usually in the millions (vs. billions or trillions in LLMs). \\n• Optimizations: Quantization, pruning, knowledge distillation, or architectural \\ntweaks. \\n• Deployment: Edge devices (phones, IoT), browsers, local servers. \\nWhile they may lack the deep reasoning and context memory of LLMs, their lightweight \\nfootprint allows for real-time, offline performance. \\nReal-World Use Cases \\n• On-device chatbots (e.g., mobile virtual assistants) \\n• Smart appliances and embedded systems \\n• Privacy-first applications (data never leaves your device)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='• Developer tools and code autocomplete on local IDEs \\n• Real-time inference in robotics or AR headsets \\nExample: Imagine asking your smart TV , “What’s a good movie like Interstellar?” and \\ngetting an instant answer without pinging the cloud. That’s an SLM at work. \\nWhy SLMs Matter in 2025 \\nAs AI becomes more integrated into daily life, the demand for low-latency, energy-\\nefficient, and privacy-respecting models is surging. \\nSLMs unlock, \\n• Offline intelligence — no internet? No problem. \\n• Data sovereignty — keep sensitive data on-device. \\n• Scalable deployment — from smartphones to smart meters. \\nAnd with projects like Phi-3, TinyLLaMA, and Apple’s rumored on-device models, SLMs \\nare entering a golden era. \\n“Not every task needs a supercomputer. Sometimes, a smart calculator does the job just \\nfine. ” \\n7. MLM — Masked Language Model \\nWhat Is a Masked Language Model? \\n \\nDiagram drawn using Draw.io (by the author) \\nBefore ChatGPT was dazzling the world with fluent essays and code generation, there was \\nBERT, and with it came the Masked Language Model (MLM).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='MLMs are trained by masking random words in a sentence and having the model predict \\nthe missing ones. It’s a bit like a fill-in-the-blank puzzle except the model learns deep, \\nbidirectional understanding of language by doing it. \\nInstead of predicting the next word like LLMs, MLMs look at the whole sentence and reason \\nabout what should go in the blank. \\nHow It Works \\nLet’s say we mask a sentence like \\n“The Eiffel Tower is located in [MASK].” \\nAn MLM will use both the left and right context (“The Eiffel Tower is located in … ”) to predict \\nthe missing word, in this case, “Paris. ” \\nThis approach helps the model understand, \\n• Syntax (grammar and structure) \\n• Semantics (meaning and relationships) \\n• Context from both directions (bidirectional learning) \\nMLMs are usually pretrained on massive text corpora and then fine-tuned for specific \\ntasks. \\nReal-World Use Cases \\nMLMs may not be flashy, but they are powerful workhorses in many AI systems, \\n• Search engines (semantic matching of queries and results) \\n• Text classification (spam detection, sentiment analysis) \\n• Named Entity Recognition (identifying names, dates, organizations) \\n• Embeddings for vector databases \\n• Pretraining for other model types \\nExample: When you search for “cheap hotels near me”, the model understands that \\n“cheap” relates to price, “hotels” are accommodations, and “near me” depends on \\nlocation. That’s deep semantic parsing powered by MLMs. \\nWhy MLMs Still Matter'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Despite the surge in autoregressive models (LLMs), MLMs continue to shine in scenarios \\nthat require: \\n• Bidirectional understanding \\n• Strong contextual representations \\n• Lower compute needs for training \\nThey are often the foundation for larger systems, or used in hybrid approaches where \\nmodels like BERT handle representation while LLMs handle generation. \\nAnd they’re evolving too with models like RoBERTa, DeBERTa, and E5 offering optimized \\nvariations for different tasks. \\n“Masked language modeling is like learning to read between the lines and then predicting \\nwhat the lines actually say. ” \\n8. SAM — Segment Anything Model \\nWhat Is SAM? \\n \\nDiagram drawn using Draw.io (by the author) \\nThe Segment Anything Model (SAM) by Meta AI is a game-changer in computer vision. \\nUnlike models that classify or detect whole objects, SAM segments, meaning it draws \\nprecise outlines around every object in an image, even those it hasn’t seen before. It'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='doesn’t just label “cat” or “dog” . It understands their shape, boundaries, and position \\nwith pixel-level precision. \\nImagine dropping a photo into a model and instantly getting every object neatly cut out. \\nThat’s the magic of SAM. \\nHow SAM Works \\nAt its core, SAM is built for promptable segmentation. You give it a prompt (a point, a box, \\nor a mask), and it returns the exact segment of the object you’re referring to. \\nIt uses, \\n• A Vision Transformer backbone to process the image \\n• An embedding-based approach to compare visual features \\n• A fast segmentation decoder that outputs masks instantly \\nAnd here’s the kicker. It can segment anything, even if it hasn’t been explicitly trained on \\nthat object class. \\nIt’s not just trained to “know” what a cat is. It’s trained to “see” any object in visual space. \\nReal-World Use Cases \\nSAM is making waves across industries, \\n• Medical Imaging: Identifying tumors or organs in scans with surgical precision \\n• Augmented Reality (AR): Real-time object detection and masking \\n• Robotics: Helping machines understand and interact with their environment \\n• Video Editing: Instant background removal, object isolation \\n• Scientific Research: Segmenting cells in microscopy images or objects in satellite \\nimages \\nExample: A medical researcher can segment a brain tumor in an MRI scan just by clicking \\nnear it. No manual outlining. No training needed. That’s SAM at work. \\nWhy SAM Is a Big Deal \\nSegmenting everything, not just known categories — unlocks a new paradigm in AI vision. \\n• Zero-shot generalization (works on unseen objects) \\n• Fast and interactive (real-time or near real-time)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='• Modular (can be paired with other models like VLMs or LAMs) \\nIt’s the LEGO brick of vision AI. Pluggable, flexible, and incredibly powerful. \\nSAM is already being integrated into larger multimodal systems. When combined with \\nVLMs (like GPT-4o or Gemini), you get models that can see, understand, and act, making it \\na vital part of the next generation of AI agents. \\nPro Tip \\nWhile SAM focuses purely on visual segmentation, you can pair it with language models or \\naction models to create powerful visual agents, like a robot that sees an object, \\nunderstands what it is, and picks it up. \\nWrapping It All Up \\nLet’s take a step back. \\nFrom LLMs writing essays, to SLMs powering chatbots on your phone, to SAM dissecting \\nimages pixel by pixel, the AI landscape is far richer than just “language models. ” \\nEach model type — LLM, LCM, MoE, LAM, VLM, SLM, MLM, SAM — is a tool in the AI \\ntoolbox, specialized for its domain, designed with specific capabilities in mind. \\nSo what’s the takeaway? \\n• Use the right model for the job, not everything needs an LLM. \\n• Understand the differences, architecture informs application. \\n• Think in systems, not silos, the future is multimodal, multi-agent, and deeply \\nspecialized. \\nWhich AI model are you most excited to explore? Already building, or just getting started? \\nDrop a comment below, share your thoughts, ask a question, or tell us what you’re curious \\nabout. Let’s learn from each other and grow together. \\nRemember, the future of AI isn’t just in the hands of experts. It’s shaped by curious minds \\nlike yours. Stay bold, keep exploring, and who knows? Your next idea could be the one that \\nchanges everything. \\nIf you found this article helpful and would like to support more content like this, you can \\nbuy me a coffee here.')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF Ingestion\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Not Everything Is an LLM.pdf\")\n",
    "pdf = loader.load()\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87ae0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7c13f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking Data\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    ")\n",
    "\n",
    "chunked_pdf = text_splitter.split_documents(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9905131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Not Everything Is an LLM: 8 AI Model Types You Need to Know in 2025 \\nBeyond ChatGPT, A beginner’s guide to today’s essential AI models \\n \\n \\nIn 2023, if you said “AI”, most people thought of ChatGPT. \\nFast-forward to 2025, and the landscape looks very different. LLMs (Large Language \\nModels) may have ignited the AI revolution, but now we’re deep into an era of specialized \\nAI models, each designed with a specific superpower. \\nYet, somehow, everyone still calls them LLMs.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='AI models, each designed with a specific superpower. \\nYet, somehow, everyone still calls them LLMs. \\nIt’s like calling every vehicle a “car”, whether it’s a bicycle, a truck, or a plane. Sure, they all \\nmove, but they’re built for very different purposes. \\nIf you’re an AI researcher, startup founder, PM, or just someone trying to keep up, \\nunderstanding the difference between an LLM, LAM, SLM, MoE, and more is no longer a \\nnice-to-have. \\nIt’s a competitive edge.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='So, Let’s break down 8 powerful AI model types and what they’re really built to do. \\n1. LLM — Large Language Model \\nWhat Is an LLM, Really? \\n \\nDiagram drawn using Draw.io (by the author) \\nImagine you’re texting a super-intelligent friend who can complete your sentences, write \\nessays, debug code, and even pretend to be Shakespeare, all in one breath. \\nThat’s essentially what an LLM (Large Language Model) does.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='essays, debug code, and even pretend to be Shakespeare, all in one breath. \\nThat’s essentially what an LLM (Large Language Model) does. \\nLLMs are trained on massive amounts of text from the internet, books, articles, code, \\ntweets to learn how language works. \\nTheir goal? To predict the next word (or token) in a sequence, based on everything that \\ncame before. \\nThink of it like supercharged autocomplete, but instead of just finishing your sentence, it'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='came before. \\nThink of it like supercharged autocomplete, but instead of just finishing your sentence, it \\ncan write an entire book, answer philosophical questions, or build a working website. \\nWhy Are LLMs So Popular? \\nThey became the poster child of AI in recent years for a few reasons, \\n• Conversational Power: ChatGPT, Claude, Gemini — all powered by LLMs. \\n• Code + Content: From blog articles to Python scripts, LLMs handle creative and \\ntechnical tasks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='• Code + Content: From blog articles to Python scripts, LLMs handle creative and \\ntechnical tasks. \\n• General Knowledge: They “know” a bit about almost everything, making them \\ngreat general-purpose tools. \\nReal-World Use Cases \\n• Writing and rewriting content'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='• Programming assistance and code generation \\n• Customer service chatbots \\n• Brainstorming ideas \\n• Language translation \\n• Education and tutoring \\nIn short, if it involves words, LLMs are likely involved. \\nBut There’s a Catch… \\nWhile LLMs seem magical, they have limitations, \\n• They can hallucinate (make things up confidently) \\n• They’re computationally expensive to run \\n• They lack true understanding or reasoning, they’re guessing based on patterns'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='• They’re computationally expensive to run \\n• They lack true understanding or reasoning, they’re guessing based on patterns \\nThat’s why new model types, built for speed, specialization, or deeper reasoning are \\nemerging fast. \\n2. LCM — Latent Consistency Model \\nWhat Is an LCM, and Why Should You Care? \\n \\nDiagram drawn using Draw.io (by the author) \\nPicture this: you’re using an AI image generator on your phone, and it gives you a crisp'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Diagram drawn using Draw.io (by the author) \\nPicture this: you’re using an AI image generator on your phone, and it gives you a crisp \\nresult in under a second, no cloud connection, no heavy lifting. \\nThat’s the power of LCMs (Latent Consistency Models).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Unlike LLMs that generate text, LCMs are designed primarily for images, and they’re \\noptimized for speed, efficiency, and small devices. They’re the fast, lightweight cousins \\nof the more heavyweight image generation models like Stable Diffusion. \\nThink of LCMs as the real-time engines of the AI world, designed to work smoothly even on \\nmobile devices or low-powered edge hardware. \\nHow Do They Work? \\nLCMs build on the concept of diffusion models, a class of models that gradually “denoise”'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='How Do They Work? \\nLCMs build on the concept of diffusion models, a class of models that gradually “denoise” \\nrandom patterns into meaningful images. But instead of needing dozens of slow steps to do \\nthis, LCMs shortcut the process by learning consistent patterns in a compressed \\n(latent) space. \\nImagine sketching a face. A normal model draws 50 lines slowly. LCM? Just a few confident \\nstrokes and it’s done. \\nReal-World Use Cases \\n• On-device image generation (think AI filters or avatars)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='strokes and it’s done. \\nReal-World Use Cases \\n• On-device image generation (think AI filters or avatars) \\n• AR/VR applications where speed is critical \\n• Faster prototyping tools for designers \\n• Real-time vision enhancement on smart cameras \\nIn essence, LCMs are the go-to model when you want fast, beautiful results without \\nneeding a supercomputer. \\nWhy They Matter in 2025 \\nWe’re moving into an era of edge computing, where devices generate content locally for'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='needing a supercomputer. \\nWhy They Matter in 2025 \\nWe’re moving into an era of edge computing, where devices generate content locally for \\nspeed and privacy. LCMs are a big part of this shift. \\nIn the future, your smart glasses or smartwatch might generate and enhance images using \\nan LCM, all on the fly. \\n3. LAM — Language Action Model \\nWhat Exactly Is a LAM?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='Diagram drawn using Draw.io (by the author) \\nIf an LLM is your chatty friend and an LCM is your quick-drawing artist, then a LAM is your \\nsmart assistant that plans, remembers, and executes tasks. \\nLAM (Language Action Model) bridges the gap between understanding language and \\ntaking meaningful actions. It doesn’t just generate text, it understands intent, \\nremembers context, and interacts with tools or environments.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='taking meaningful actions. It doesn’t just generate text, it understands intent, \\nremembers context, and interacts with tools or environments. \\nThink of LAMs as the backbone of AI agents, the kind of models that can help automate \\ntasks, operate software tools, or plan multi-step actions like booking a trip or debugging \\ncode. \\nHow Does It Work? \\nLAMs typically combine, \\n• LLMs for natural language understanding, \\n• Memory modules for keeping track of past actions or inputs,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='LAMs typically combine, \\n• LLMs for natural language understanding, \\n• Memory modules for keeping track of past actions or inputs, \\n• Planners that can break down complex tasks, \\n• Tool use capabilities to actually execute steps (e.g., via APIs or interfaces). \\nImagine asking your AI, “Book a flight to Tokyo, compare hotel prices, and set a \\nreminder for my visa appointment. ” \\nA pure LLM might just give you suggestions.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='reminder for my visa appointment. ” \\nA pure LLM might just give you suggestions. \\nA LAM? It acts, checking calendars, querying APIs, and building a task flow behind the \\nscenes.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Real-World Use Cases \\n• AI agents that automate workflows (e.g., Zapier AI, Devin) \\n• Digital assistants that interact with apps and services \\n• Customer support bots that solve problems, not just reply \\n• Productivity tools that complete tasks based on instructions \\n• Robotics, where language input controls physical actions \\nWhy LAMs Matter in 2025 \\nLLMs changed the game by understanding text. But LAMs are pushing things forward by \\ndoing things.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Why LAMs Matter in 2025 \\nLLMs changed the game by understanding text. But LAMs are pushing things forward by \\ndoing things. \\nIn a world of increasing automation, LAMs are unlocking AI that can work across apps, \\nunderstand long-term goals, and adapt to changing environments. \\nImagine an AI that not only drafts your email but also sends it, follows up, and schedules a \\nmeeting, all based on one prompt. \\n4. MoE — Mixture of Experts \\nWhat Is a MoE Model?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='meeting, all based on one prompt. \\n4. MoE — Mixture of Experts \\nWhat Is a MoE Model? \\n \\nDiagram drawn using Draw.io (by the author)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Imagine you’re asking a big question and instead of getting an answer from one generalist, \\nyou’re directed to a team of specialists, each an expert in a narrow domain. \\nThat’s what MoE (Mixture of Experts) models do. \\nA Mixture of Experts model is made up of many sub-models (“experts”), but when a \\nprompt comes in, only a few experts are activated based on what’s relevant. This makes \\nthe model scalable and efficient, because not every expert is used every time.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='the model scalable and efficient, because not every expert is used every time. \\nThink of it like consulting the best surgeon for surgery, the best chef for cooking, and the \\nbest mechanic for your car, all within one AI. \\nHow It Works \\nMoE uses a “router”, a smart internal system that decides which expert(s) to activate \\nbased on your input. \\n• The router evaluates the input. \\n• It chooses the top N experts (often 2 out of 100+).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='based on your input. \\n• The router evaluates the input. \\n• It chooses the top N experts (often 2 out of 100+). \\n• Only those selected experts process the input and return an output. \\n• This output is combined and returned to the user. \\nSo you get targeted intelligence with minimal compute overhead. \\nReal-World Use Cases \\n• High-performance AI at scale (e.g., Google’s Switch Transformer, GShard) \\n• Efficient cloud inference — fewer resources, faster outputs'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='• High-performance AI at scale (e.g., Google’s Switch Transformer, GShard) \\n• Efficient cloud inference — fewer resources, faster outputs \\n• Domain-specialized assistants (e.g., a medical expert vs. a legal expert) \\n• Multilingual systems — experts for different languages \\n• Fine-grained personalization — experts tuned to user behavior or tasks \\nWhy MoE Models Matter in 2025 \\nWith AI models growing into hundreds of billions of parameters, compute costs are'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Why MoE Models Matter in 2025 \\nWith AI models growing into hundreds of billions of parameters, compute costs are \\nbecoming a bottleneck. MoE models provide a brilliant workaround, you scale wide \\nwithout scaling heavy. \\nBy activating only what’s needed, MoEs offer a massive increase in performance without \\nneeding supercomputers for every query.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Imagine a model that’s 10x larger but only costs as much to run as a model half its size. \\nThat’s the power of MoE. \\nThey also make way for more modular and expandable systems, where new experts can \\nbe added without retraining the entire model. \\n5. VLM — Vision Language Model \\nWhat Is a VLM? \\n \\nDiagram drawn using Draw.io (by the author) \\nImagine an AI that sees an image and reads your caption or query and then responds with \\ndeep understanding of both.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Imagine an AI that sees an image and reads your caption or query and then responds with \\ndeep understanding of both. \\nThat’s the magic of a Vision Language Model (VLM). These models are designed to \\nprocess and understand both visual and textual inputs simultaneously. \\nThey’re like the Swiss Army knife of AI, combining the perception of vision models with the \\nreasoning power of language models. \\nHow It Works'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='They’re like the Swiss Army knife of AI, combining the perception of vision models with the \\nreasoning power of language models. \\nHow It Works \\nAt the core of a VLM is a shared embedding space, a special zone where images and text \\nare mapped into similar “meaningful” numerical representations. \\nThis allows the model to match images to descriptions, answer questions about visual \\ncontent, or even generate text from images and vice versa. \\nHere’s a simplified flow,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='content, or even generate text from images and vice versa. \\nHere’s a simplified flow, \\n1. Image goes through a vision encoder (like a modified transformer or CNN).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='2. Text goes through a language encoder (like BERT or GPT). \\n3. Both are aligned in a shared latent space for cross-modal understanding. \\n4. The model produces outputs such as answers, captions, classifications, etc. \\nReal-World Use Cases \\n• Multimodal assistants (e.g., ChatGPT-4o, Gemini) \\n• Image captioning \\n• Visual question answering (VQA) \\n• Search engines that understand both text & image queries \\n• Accessibility tools (e.g., for visually impaired users)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='• Search engines that understand both text & image queries \\n• Accessibility tools (e.g., for visually impaired users) \\n• Robotics — interpreting surroundings using both vision and instruction \\n• AR/VR — contextual interaction with the real world \\nExample: You upload a photo of a cracked phone screen and ask, “Can I still use this?” A \\nVLM can analyze the image, understand the question, and respond helpfully. \\nWhy VLMs Matter in 2025'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='VLM can analyze the image, understand the question, and respond helpfully. \\nWhy VLMs Matter in 2025 \\nIn a world where digital content is increasingly visual, we need models that go beyond \\ntext-only capabilities. VLMs are foundational to, \\n• Multimodal search \\n• Context-aware agents \\n• Assistive AI for real-world perception \\nThey are key to bridging the gap between language-driven interfaces and the visual-first \\nworld we live in, making AI more intuitive and human-friendly.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='world we live in, making AI more intuitive and human-friendly. \\nVLMs also serve as the building blocks for embodied AI. Systems that can “see, ” \\n“understand, ” and “act” in physical or virtual environments. \\n6. SLM — Small Language Model \\nWhat Is a Small Language Model?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Diagram drawn using Draw.io (by the author) \\nWhile LLMs grab the spotlight with their massive scale, Small Language Models (SLMs) \\nwork quietly in the background. On your phone, your laptop, or even your smart toaster. \\nSLMs are compact, efficient language models designed to deliver fast, low-latency \\nresponses on limited hardware. \\nThink of them as the LLM’s minimalistic cousin, less compute-hungry but still impressively \\ncapable. \\nHow It Works'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='responses on limited hardware. \\nThink of them as the LLM’s minimalistic cousin, less compute-hungry but still impressively \\ncapable. \\nHow It Works \\nSLMs are typically built using the same transformer architecture as LLMs, but with fewer \\nparameters and optimized inference paths. \\n• Parameter count: Usually in the millions (vs. billions or trillions in LLMs). \\n• Optimizations: Quantization, pruning, knowledge distillation, or architectural \\ntweaks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='• Optimizations: Quantization, pruning, knowledge distillation, or architectural \\ntweaks. \\n• Deployment: Edge devices (phones, IoT), browsers, local servers. \\nWhile they may lack the deep reasoning and context memory of LLMs, their lightweight \\nfootprint allows for real-time, offline performance. \\nReal-World Use Cases \\n• On-device chatbots (e.g., mobile virtual assistants) \\n• Smart appliances and embedded systems \\n• Privacy-first applications (data never leaves your device)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='• Developer tools and code autocomplete on local IDEs \\n• Real-time inference in robotics or AR headsets \\nExample: Imagine asking your smart TV , “What’s a good movie like Interstellar?” and \\ngetting an instant answer without pinging the cloud. That’s an SLM at work. \\nWhy SLMs Matter in 2025 \\nAs AI becomes more integrated into daily life, the demand for low-latency, energy-\\nefficient, and privacy-respecting models is surging. \\nSLMs unlock, \\n• Offline intelligence — no internet? No problem.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='efficient, and privacy-respecting models is surging. \\nSLMs unlock, \\n• Offline intelligence — no internet? No problem. \\n• Data sovereignty — keep sensitive data on-device. \\n• Scalable deployment — from smartphones to smart meters. \\nAnd with projects like Phi-3, TinyLLaMA, and Apple’s rumored on-device models, SLMs \\nare entering a golden era. \\n“Not every task needs a supercomputer. Sometimes, a smart calculator does the job just \\nfine. ” \\n7. MLM — Masked Language Model'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='“Not every task needs a supercomputer. Sometimes, a smart calculator does the job just \\nfine. ” \\n7. MLM — Masked Language Model \\nWhat Is a Masked Language Model? \\n \\nDiagram drawn using Draw.io (by the author) \\nBefore ChatGPT was dazzling the world with fluent essays and code generation, there was \\nBERT, and with it came the Masked Language Model (MLM).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='MLMs are trained by masking random words in a sentence and having the model predict \\nthe missing ones. It’s a bit like a fill-in-the-blank puzzle except the model learns deep, \\nbidirectional understanding of language by doing it. \\nInstead of predicting the next word like LLMs, MLMs look at the whole sentence and reason \\nabout what should go in the blank. \\nHow It Works \\nLet’s say we mask a sentence like \\n“The Eiffel Tower is located in [MASK].”'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='about what should go in the blank. \\nHow It Works \\nLet’s say we mask a sentence like \\n“The Eiffel Tower is located in [MASK].” \\nAn MLM will use both the left and right context (“The Eiffel Tower is located in … ”) to predict \\nthe missing word, in this case, “Paris. ” \\nThis approach helps the model understand, \\n• Syntax (grammar and structure) \\n• Semantics (meaning and relationships) \\n• Context from both directions (bidirectional learning)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='• Syntax (grammar and structure) \\n• Semantics (meaning and relationships) \\n• Context from both directions (bidirectional learning) \\nMLMs are usually pretrained on massive text corpora and then fine-tuned for specific \\ntasks. \\nReal-World Use Cases \\nMLMs may not be flashy, but they are powerful workhorses in many AI systems, \\n• Search engines (semantic matching of queries and results) \\n• Text classification (spam detection, sentiment analysis)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='• Search engines (semantic matching of queries and results) \\n• Text classification (spam detection, sentiment analysis) \\n• Named Entity Recognition (identifying names, dates, organizations) \\n• Embeddings for vector databases \\n• Pretraining for other model types \\nExample: When you search for “cheap hotels near me”, the model understands that \\n“cheap” relates to price, “hotels” are accommodations, and “near me” depends on \\nlocation. That’s deep semantic parsing powered by MLMs.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='“cheap” relates to price, “hotels” are accommodations, and “near me” depends on \\nlocation. That’s deep semantic parsing powered by MLMs. \\nWhy MLMs Still Matter'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Despite the surge in autoregressive models (LLMs), MLMs continue to shine in scenarios \\nthat require: \\n• Bidirectional understanding \\n• Strong contextual representations \\n• Lower compute needs for training \\nThey are often the foundation for larger systems, or used in hybrid approaches where \\nmodels like BERT handle representation while LLMs handle generation. \\nAnd they’re evolving too with models like RoBERTa, DeBERTa, and E5 offering optimized \\nvariations for different tasks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='And they’re evolving too with models like RoBERTa, DeBERTa, and E5 offering optimized \\nvariations for different tasks. \\n“Masked language modeling is like learning to read between the lines and then predicting \\nwhat the lines actually say. ” \\n8. SAM — Segment Anything Model \\nWhat Is SAM? \\n \\nDiagram drawn using Draw.io (by the author) \\nThe Segment Anything Model (SAM) by Meta AI is a game-changer in computer vision.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='What Is SAM? \\n \\nDiagram drawn using Draw.io (by the author) \\nThe Segment Anything Model (SAM) by Meta AI is a game-changer in computer vision. \\nUnlike models that classify or detect whole objects, SAM segments, meaning it draws \\nprecise outlines around every object in an image, even those it hasn’t seen before. It'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='doesn’t just label “cat” or “dog” . It understands their shape, boundaries, and position \\nwith pixel-level precision. \\nImagine dropping a photo into a model and instantly getting every object neatly cut out. \\nThat’s the magic of SAM. \\nHow SAM Works \\nAt its core, SAM is built for promptable segmentation. You give it a prompt (a point, a box, \\nor a mask), and it returns the exact segment of the object you’re referring to. \\nIt uses, \\n• A Vision Transformer backbone to process the image'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='or a mask), and it returns the exact segment of the object you’re referring to. \\nIt uses, \\n• A Vision Transformer backbone to process the image \\n• An embedding-based approach to compare visual features \\n• A fast segmentation decoder that outputs masks instantly \\nAnd here’s the kicker. It can segment anything, even if it hasn’t been explicitly trained on \\nthat object class. \\nIt’s not just trained to “know” what a cat is. It’s trained to “see” any object in visual space. \\nReal-World Use Cases'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='that object class. \\nIt’s not just trained to “know” what a cat is. It’s trained to “see” any object in visual space. \\nReal-World Use Cases \\nSAM is making waves across industries, \\n• Medical Imaging: Identifying tumors or organs in scans with surgical precision \\n• Augmented Reality (AR): Real-time object detection and masking \\n• Robotics: Helping machines understand and interact with their environment \\n• Video Editing: Instant background removal, object isolation'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='• Robotics: Helping machines understand and interact with their environment \\n• Video Editing: Instant background removal, object isolation \\n• Scientific Research: Segmenting cells in microscopy images or objects in satellite \\nimages \\nExample: A medical researcher can segment a brain tumor in an MRI scan just by clicking \\nnear it. No manual outlining. No training needed. That’s SAM at work. \\nWhy SAM Is a Big Deal'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='near it. No manual outlining. No training needed. That’s SAM at work. \\nWhy SAM Is a Big Deal \\nSegmenting everything, not just known categories — unlocks a new paradigm in AI vision. \\n• Zero-shot generalization (works on unseen objects) \\n• Fast and interactive (real-time or near real-time)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='• Modular (can be paired with other models like VLMs or LAMs) \\nIt’s the LEGO brick of vision AI. Pluggable, flexible, and incredibly powerful. \\nSAM is already being integrated into larger multimodal systems. When combined with \\nVLMs (like GPT-4o or Gemini), you get models that can see, understand, and act, making it \\na vital part of the next generation of AI agents. \\nPro Tip \\nWhile SAM focuses purely on visual segmentation, you can pair it with language models or'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='a vital part of the next generation of AI agents. \\nPro Tip \\nWhile SAM focuses purely on visual segmentation, you can pair it with language models or \\naction models to create powerful visual agents, like a robot that sees an object, \\nunderstands what it is, and picks it up. \\nWrapping It All Up \\nLet’s take a step back. \\nFrom LLMs writing essays, to SLMs powering chatbots on your phone, to SAM dissecting \\nimages pixel by pixel, the AI landscape is far richer than just “language models. ”'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='images pixel by pixel, the AI landscape is far richer than just “language models. ” \\nEach model type — LLM, LCM, MoE, LAM, VLM, SLM, MLM, SAM — is a tool in the AI \\ntoolbox, specialized for its domain, designed with specific capabilities in mind. \\nSo what’s the takeaway? \\n• Use the right model for the job, not everything needs an LLM. \\n• Understand the differences, architecture informs application. \\n• Think in systems, not silos, the future is multimodal, multi-agent, and deeply \\nspecialized.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='• Think in systems, not silos, the future is multimodal, multi-agent, and deeply \\nspecialized. \\nWhich AI model are you most excited to explore? Already building, or just getting started? \\nDrop a comment below, share your thoughts, ask a question, or tell us what you’re curious \\nabout. Let’s learn from each other and grow together. \\nRemember, the future of AI isn’t just in the hands of experts. It’s shaped by curious minds'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-11T03:18:01+05:30', 'author': 'R.D.P.R. RANAGE', 'moddate': '2025-06-11T03:18:01+05:30', 'source': 'Not Everything Is an LLM.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='about. Let’s learn from each other and grow together. \\nRemember, the future of AI isn’t just in the hands of experts. It’s shaped by curious minds \\nlike yours. Stay bold, keep exploring, and who knows? Your next idea could be the one that \\nchanges everything. \\nIf you found this article helpful and would like to support more content like this, you can \\nbuy me a coffee here.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0fd503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "Not Everything Is an LLM: 8 AI Model Types You Need to Know in 2025 \n",
      "Beyond ChatGPT, A beginner’s guide to today’s essential AI models \n",
      " \n",
      " \n",
      "In 2023, if you said “AI”, most people thought of ChatGPT. \n",
      "Fast-forward to 2025, and the landscape looks very different. LLMs (Large Language \n",
      "Models) may have ignited the AI revolution, but now we’re deep into an era of specialized \n",
      "AI models, each designed with a specific superpower. \n",
      "Yet, somehow, everyone still calls them LLMs. \n",
      "\n",
      "--- Chunk 2 ---\n",
      "AI models, each designed with a specific superpower. \n",
      "Yet, somehow, everyone still calls them LLMs. \n",
      "It’s like calling every vehicle a “car”, whether it’s a bicycle, a truck, or a plane. Sure, they all \n",
      "move, but they’re built for very different purposes. \n",
      "If you’re an AI researcher, startup founder, PM, or just someone trying to keep up, \n",
      "understanding the difference between an LLM, LAM, SLM, MoE, and more is no longer a \n",
      "nice-to-have. \n",
      "It’s a competitive edge. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(chunked_pdf[:2]):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(doc.page_content,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Embedding and Vector Store\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    chunked_pdf,\n",
    "    embeddings,\n",
    "    collection_name=\"example_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1586494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS database\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "faiss_vector_store = FAISS.from_documents(\n",
    "    chunked_pdf,\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3202198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine you’re asking a big question and instead of getting an answer from one generalist, \\nyou’re directed to a team of specialists, each an expert in a narrow domain. \\nThat’s what MoE (Mixture of Experts) models do. \\nA Mixture of Experts model is made up of many sub-models (“experts”), but when a \\nprompt comes in, only a few experts are activated based on what’s relevant. This makes \\nthe model scalable and efficient, because not every expert is used every time.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector database Querying\n",
    "\n",
    "query = \"What is mixture of experts?\"\n",
    "results = faiss_vector_store.similarity_search(query)\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbc0f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "\n",
    "# llm = Ollama(model=llama3)\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "891dc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bf55b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sri Lanka has two capitals:\n",
      "\n",
      "*   **Colombo:** The commercial capital and largest city.\n",
      "*   **Sri Jayawardenepura Kotte:** The administrative capital.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "response = llm.invoke(\"What's the capital of Sri Lanka?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54f494b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                            Answer the following question based only on the provided context.\n",
    "                                            Think step by step before providing a detailed answer. \n",
    "                                            Explain the answer in a way that is easy to understand using only the provided context.\n",
    "                                            Do NOT include phrases like \"Based on the context\" or \"Here's the answer\".\n",
    "                                            ONLY return the answer.\n",
    "                                            <context>\n",
    "                                            {context}\n",
    "                                            </context>\n",
    "                                            Question: {input}\n",
    "                                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1188a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stuff Document Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "doc_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f90b9465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A85D8D2710>, search_kwargs={})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = faiss_vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e60e70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Chain\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, doc_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c904ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The specialized AI models mentioned are LCM, MoE, LAM, VLM, SLM, MLM, and SAM.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\n",
    "    \"input\": \"What are the Specialized AI models rather than LLMs?\"\n",
    "})\n",
    "\n",
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
